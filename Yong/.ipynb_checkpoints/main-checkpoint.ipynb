{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: CUDA_DEVICE_ORDER=PCI_BUS_ID\n",
      "env: CUDA_VISIBLE_DEVICES=1,2,3,4,5,6,7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "%env CUDA_DEVICE_ORDER=PCI_BUS_ID\n",
    "%env CUDA_VISIBLE_DEVICES=1,2,3,4,5,6,7\n",
    "no_gpu = 7\n",
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import scipy\n",
    "import scipy.stats\n",
    "import operator\n",
    "import pandas as pd\n",
    "from __future__ import print_function\n",
    "import os\n",
    "import cPickle as pickle\n",
    "import math\n",
    "from time import time\n",
    "from datetime import datetime\n",
    "from keras.optimizers import Adam\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "np.random.seed(1337)  # for reproducibility\n",
    "\n",
    "nb_epoch = 500  # number of epoch at training stage\n",
    "nb_epoch_cont = 500  # number of epoch at training (cont) stage\n",
    "batch_size = 15  # batch size\n",
    "\n",
    "lr = 0.001  # learning rate\n",
    "len_closeness = 15  # length of closeness dependent sequence\n",
    "nb_residual_unit = 4   # number of residual units\n",
    "year_test = 2006\n",
    "nb_flow = 1  # there are two types of flows: new-flow and end-flow\n",
    "path_result = 'RET'\n",
    "path_model = 'MODEL'\n",
    "\n",
    "if os.path.isdir(path_result) is False:\n",
    "    os.mkdir(path_result)\n",
    "if os.path.isdir(path_model) is False:\n",
    "    os.mkdir(path_model)\n",
    "data_path = '/notebooks/workspace/flood/www.ncei.noaa.gov/data/precipitation-persiann/'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from persiann import sample_construction\n",
    "if os.path.isfile('X.npy') is False: \n",
    "    print ('start creating samples.')\n",
    "    sc = sample_construction(data_path=data_path,end_year=2016)\n",
    "    sc.create_samples(target_river = 'G')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "E:  (4148, 5) X:  (4148, 15, 92, 188) Y:  (4148, 1)\n"
     ]
    }
   ],
   "source": [
    "E = np.load('E.npy') #external input\n",
    "X = np.load('X.npy')\n",
    "Y = pd.read_pickle('Y_df.pkl')\n",
    "map_height, map_width = X.shape[2], X.shape[3]\n",
    "print('E: ',E.shape,'X: ',X.shape,'Y: ',Y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "168.5450439453125\n"
     ]
    }
   ],
   "source": [
    "print(np.max(X[:10]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(568731529,)\n"
     ]
    }
   ],
   "source": [
    "print (X[X>0].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(507425591,)\n"
     ]
    }
   ],
   "source": [
    "print (X[X==0].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def distribution_plot(y,fit):\n",
    "    overall_min = np.min(y)\n",
    "    overall_max = np.max(y)\n",
    "    #print (overall_max,overall_min)\n",
    "    bins = np.linspace(overall_min, overall_max, 50)\n",
    "    #print(bins)   \n",
    "    fig = plt.figure()\n",
    "    fig.set_size_inches(15, 10)\n",
    "    print (y.shape)  \n",
    "    n, bins, patches = plt.hist(y, bins, alpha=0.5, density=fit, facecolor='g')#log=True\n",
    "    #print (n)\n",
    "    #print (bins)\n",
    "    #print(patches)\n",
    "#(x, 50, density=True, facecolor='g', alpha=0.75)\n",
    "    #print(bins)\n",
    "    #dist_names = ['rayleigh', 'norm', 'pareto']\n",
    "    #dist_names = ['alpha', 'anglit', 'arcsine', 'beta', 'betaprime', 'bradford', 'burr', 'cauchy', 'chi', 'chi2', 'cosine', 'dgamma', 'dweibull', 'erlang', 'expon', 'exponweib', 'exponpow', 'f', 'fatiguelife', 'fisk', 'foldcauchy', 'foldnorm', 'frechet_r', 'frechet_l', 'genlogistic', 'genpareto', 'genexpon', 'genextreme', 'gausshyper', 'gamma', 'gengamma', 'genhalflogistic', 'gilbrat', 'gompertz', 'gumbel_r', 'gumbel_l', 'halfcauchy', 'halflogistic', 'halfnorm', 'hypsecant', 'invgamma', 'invgauss', 'invweibull', 'johnsonsb', 'johnsonsu', 'ksone', 'kstwobign', 'laplace', 'logistic', 'loggamma', 'loglaplace', 'lognorm', 'lomax', 'maxwell', 'mielke', 'nakagami', 'ncx2', 'ncf', 'nct', 'norm', 'pareto', 'pearson3', 'powerlaw', 'powerlognorm', 'powernorm', 'rdist', 'reciprocal', 'rayleigh', 'rice', 'recipinvgauss', 'semicircular', 't', 'triang', 'truncexpon', 'truncnorm', 'tukeylambda', 'uniform', 'vonmises', 'wald', 'weibull_min', 'weibull_max', 'wrapcauchy']\n",
    "    #dist_names = ['invgauss', 'foldcauchy', 'lomax', 'halfcauchy', 'pareto', 'alpha', 'genexpon', 'expon', 'gompertz', 'halflogistic', 'genhalflogistic', 'halfnorm', 'foldnorm', 'gilbrat', 'uniform', 'ksone', 'truncnorm', 'wald', 'bradford', 'triang', 'truncexpon', 'semicircular', 'kstwobign', 'rice', 'rayleigh', 'frechet_l', 'wrapcauchy', 'gumbel_r', 'genlogistic', 'weibull_max', 'maxwell', 'anglit', 'norm', 'loggamma', 'logistic', 'hypsecant', 'cauchy', 'gumbel_l', 'powernorm', 'laplace', 'reciprocal', 'cosine']\n",
    "    dist_names = ['pareto','norm','alpha','logistic', 'hypsecant', 'cauchy', 'gumbel_l', 'powernorm', 'laplace', 'reciprocal']#'reciprocal'\n",
    "    #dist_names = ['gumbel_l','logistic','norm','alpha','cauchy', 'laplace']# \n",
    "    #dist_names = ['pareto','norm','genpareto', 'halfnorm', 'expon' ]\n",
    "    #dist_names = ['lognorm']\n",
    "    #dist_names = ['arcsine', 'truncexpon', 'semicircular', 'anglit', 'triang', 'genhalflogistic', 'lomax', 'expon', 'betaprime', 'exponpow', 'loglaplace', 'fisk', 'exponweib', 'invweibull', 'gumbel_r', 'genlogistic',  'genpareto',  'foldnorm', 'kstwobign','halfcauchy',  'rayleigh',  'rice', 'maxwell',  'cosine', 'mielke',  'genexpon',  'dgamma']\n",
    "    #dist_names = ['truncexpon', 'semicircular', 'anglit', 'triang', 'genhalflogistic', 'loglaplace', 'betaprime','fisk', 'exponweib', 'invweibull', 'gumbel_r', 'genlogistic',  'genpareto',  'foldnorm', 'kstwobign','halfcauchy',  'rayleigh',  'rice', 'maxwell',  'cosine', 'mielke',  'genexpon',  'dgamma']\n",
    "    \n",
    "    dic = {}\n",
    "    print('here111111')\n",
    "    if fit:\n",
    "        for dist_name in dist_names:\n",
    "            dist = getattr(scipy.stats, dist_name)\n",
    "            param = dist.fit(y)\n",
    "            print('here2222222')\n",
    "            pdf_fitted = dist.pdf(bins, *param[:-2], loc=param[-2], scale=param[-1])       \n",
    "            NLL = -np.sum(np.log(pdf_fitted))\n",
    "            print (\"Dist: {0}, NLL: {1}\".format(dist_name, NLL))\n",
    "            dic[dist_name]=NLL\n",
    "            plt.plot(bins, pdf_fitted, label=dist_name+', NLL: '+str(NLL))\n",
    "        sorted_dic = sorted(dic.items(), key=operator.itemgetter(1))\n",
    "        print (sorted_dic)\n",
    "    #plt.xlim(xmin,xmax)\n",
    "    #plt.ylim(ymin,ymax)\n",
    "    plt.legend(loc='upper right')\n",
    "    plt.xlabel('Daily Stream Flow')\n",
    "    plt.ylabel('Number of Days')\n",
    "    plt.show()\n",
    "#plt.xticks(bins, [\"2^%s\" % i for i in bins])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4148,)\n",
      "here111111\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1080x720 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "min: -0.6931471805599453\n",
      "max: 2.2223159892012707\n",
      "mean: -0.6406405252644741\n",
      "median: -0.6931471805599453\n",
      "standard deviation: 0.25961443507311804\n",
      "75% percentile: -0.6931471805599453\n",
      ">75% percentile ratio= 1.0\n"
     ]
    }
   ],
   "source": [
    "data = X[:,0,10,10]#np.array(np.log(1+Y))#np.log(0.5+y)\n",
    "data = np.array(np.log(0.5+data))\n",
    "sorted_dic = distribution_plot(data,False)\n",
    "print ('min: '+str(np.min(data)))\n",
    "print ('max: '+str(np.max(data)))\n",
    "print ('mean: '+str(np.mean(data)))\n",
    "print ('median: '+str(np.median(data)))\n",
    "print ('standard deviation: '+str(np.std(data)))\n",
    "print ('75% percentile: '+str(np.percentile(data,75)))\n",
    "ratio = (np.max(data)-np.percentile(data,75))/(np.max(data) - np.min(data))\n",
    "print ('>75% percentile ratio= '+str(ratio))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ymax,ymin = 450,0\n",
    "#xmax,xmin = 2.2,0\n",
    "#xmax,xmin = 2200,0\n",
    "#distribution_plot(y,omax,omin)\n",
    "data = Y#np.array(np.log(1+Y))#np.log(0.5+y)\n",
    "sorted_dic = distribution_plot(data)\n",
    "print ('min: '+str(np.min(data)))\n",
    "print ('max: '+str(np.max(data)))\n",
    "print ('mean: '+str(np.mean(data)))\n",
    "print ('median: '+str(np.median(data)))\n",
    "print ('standard deviation: '+str(np.std(data)))\n",
    "print ('75% percentile: '+str(np.percentile(data,75)))\n",
    "ratio = (np.max(data)-np.percentile(data,75))/(np.max(data) - np.min(data))\n",
    "print ('>75% percentile ratio= '+str(ratio))\n",
    "#data =np.log(1+y)/np.log(1.6) \n",
    "#distribution_plot(data,omax,omin)\n",
    "#data =np.log(1+y)/np.log(1.5) \n",
    "#distribution_plot(data,omax,omin)\n",
    "#data =np.log(1+y)/np.log(1.1) \n",
    "#distribution_plot(data,omax,omin)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y = np.log(1+Y)\n",
    "train_idx  = Y.index.year < year_test\n",
    "test_idx  = Y.index.year >= year_test\n",
    "#X=np.reshape(X,(:, np.newaxis,...))\n",
    "#X = X[:, np.newaxis,...]\n",
    "E_train, X_train, Y_train, E_test, X_test, Y_test = E[train_idx], X[train_idx],Y.iloc[train_idx],E[test_idx],X[test_idx],Y.iloc[test_idx]\n",
    "print ('E_train shape', E_train.shape,'X_train shape', X_train.shape, 'Y_train shape', Y_train.shape,'E_test shape', E_test.shape,'X_test shape', X_test.shape, 'Y_test shape', Y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print (Y[:50])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import backend as K\n",
    "#Root Mean Squared Error\n",
    "def rmse(y_true, y_pred):\n",
    "    return K.sqrt(K.mean(K.square(y_pred - y_true), axis=-1))\n",
    "#Root Mean Squared Logarithmic Error\n",
    "def rmsle(y_true, y_pred):\n",
    "    return K.sqrt(K.mean(K.square(tf.log1p(y_pred) - tf.log1p(y_true))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import residualnet as rn\n",
    "from keras.utils import multi_gpu_model\n",
    "\n",
    "def build_model(external_dim):\n",
    "    c_conf = (len_closeness, nb_flow, map_height,\n",
    "              map_width) if len_closeness > 0 else None\n",
    "\n",
    "    model = rn.stresnet(c_conf=c_conf, p_conf=None, t_conf=None,\n",
    "                     external_dim=external_dim, nb_residual_unit=nb_residual_unit, is_3D=False, batchNormalization=False) \n",
    "    \n",
    "    parallel_model = multi_gpu_model(model, gpus=no_gpu)\n",
    "    \n",
    "    adam = Adam(lr=lr)\n",
    "    parallel_model.compile(loss='mse', optimizer=adam, metrics=[rmse])\n",
    "    parallel_model.summary()\n",
    "    # from keras.utils.visualize_util import plot\n",
    "    # plot(model, to_file='model.png', show_shapes=True)\n",
    "    return parallel_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "external_dim = E_train.shape[1]\n",
    "model = build_model(external_dim)\n",
    "hyperparams_name = 'c{}.resunit{}.lr{}'.format(\n",
    "    len_closeness, nb_residual_unit, lr)\n",
    "fname_param = os.path.join('MODEL', '{}.best.h5'.format(hyperparams_name))\n",
    "\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=20, mode='min')\n",
    "model_checkpoint = ModelCheckpoint(\n",
    "    fname_param, monitor='val_loss', verbose=0, save_best_only=True, mode='min')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training with early stopping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"training model...\")\n",
    "X_tr=[X_train,E_train]\n",
    "X_te=[X_test,E_test]\n",
    "history = model.fit(X_tr, Y_train,\n",
    "                    epochs=nb_epoch,\n",
    "                    batch_size=batch_size,\n",
    "                    validation_split=0.1,\n",
    "                    callbacks=[early_stopping, model_checkpoint],\n",
    "                    verbose=1)\n",
    "model.save_weights(os.path.join(\n",
    "    path_model, '{}.h5'.format(hyperparams_name)), overwrite=True)\n",
    "pickle.dump((history.history), open(os.path.join(\n",
    "    path_result, '{}.history.pkl'.format(hyperparams_name)), 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# summarize history for root mean squared error\n",
    "f, (ax1,ax2) = plt.subplots(2, 1, sharex=True)\n",
    "f.set_size_inches(16, 8)\n",
    "f.subplots_adjust(top=1.85)\n",
    "ax1.tick_params(axis='both', which='major', labelsize=15)\n",
    "ax1.set_title('Root Mean Squared Error',size=25)\n",
    "ax1.set_ylabel('root mean squared error',size=20)\n",
    "#ax1.set_xlabel('epoch',size=20)\n",
    "rmse_train=ax1.plot(history.history['rmse'])\n",
    "rmse_val=ax1.plot(history.history['val_rmse'])\n",
    "ax1.legend( ( rmse_train[0], rmse_val[0]), ('Training','Validation'),fontsize=15)\n",
    "\n",
    "ax2.tick_params(axis='both', which='major', labelsize=15)\n",
    "ax2.set_title('Loss',size=25)\n",
    "ax2.set_ylabel('Loss',size=20)\n",
    "ax2.set_xlabel('Epoch',size=20)\n",
    "loss_train=ax2.plot(history.history['loss'])\n",
    "loss_val=ax2.plot(history.history['val_loss'])\n",
    "\n",
    "ax2.legend( ( loss_train[0], loss_val[0]), ('Training','Validation'),fontsize=15)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluation using the model given by early stopping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('=' * 50)\n",
    "print('evaluating using the model that has the best loss on the valid set')\n",
    "model.load_weights(fname_param)\n",
    "score = model.evaluate(X_tr, Y_train, batch_size=batch_size, verbose=0)\n",
    "print('Train score: %.6f rmse (norm): %.6f' %\n",
    "      (score[0], score[1]))\n",
    "\n",
    "score = model.evaluate(\n",
    "    X_te, Y_test, batch_size=batch_size, verbose=0)\n",
    "print('Test score: %.6f rmse (norm): %.6f' %\n",
    "      (score[0], score[1]))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Continue training without early stopping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('=' * 50)\n",
    "print(\"training model (cont)...\")\n",
    "fname_param = os.path.join(\n",
    "    path_model, '{}.cont.best.h5'.format(hyperparams_name))\n",
    "model_checkpoint = ModelCheckpoint(\n",
    "    fname_param, monitor='mse', verbose=0, save_best_only=True, mode='min')\n",
    "history = model.fit(X_tr, Y_train, epochs=nb_epoch_cont, verbose=1, batch_size=batch_size, callbacks=[\n",
    "                    model_checkpoint], validation_data=(X_te, Y_test))\n",
    "pickle.dump((history.history), open(os.path.join(\n",
    "    path_result, '{}.cont.history.pkl'.format(hyperparams_name)), 'wb'))\n",
    "model.save_weights(os.path.join(\n",
    "    path_model, '{}_cont.h5'.format(hyperparams_name)), overwrite=True)\n",
    "\n",
    "print('=' * 10)\n",
    "print('evaluating using the final model')\n",
    "score = model.evaluate(X_tr, Y_train, batch_size=batch_size, verbose=0)\n",
    "print('Train score: %.6f rmse (norm): %.6f' %\n",
    "      (score[0], score[1]))\n",
    "score = model.evaluate(\n",
    "    X_te, Y_test, batch_size=batch_size, verbose=0)\n",
    "print('Test score: %.6f rmse (norm): %.6f' %\n",
    "      (score[0], score[1]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# summarize history for root mean squared error\n",
    "f, (ax1,ax2) = plt.subplots(2, 1, sharex=True)\n",
    "f.set_size_inches(16, 8)\n",
    "f.subplots_adjust(top=1.85)\n",
    "ax1.tick_params(axis='both', which='major', labelsize=15)\n",
    "ax1.set_title('Root Mean Squared Error',size=25)\n",
    "ax1.set_ylabel('root mean squared error',size=20)\n",
    "#ax1.set_xlabel('epoch',size=20)\n",
    "rmse_train=ax1.plot(history.history['rmse'])\n",
    "rmse_val=ax1.plot(history.history['val_rmse'])\n",
    "ax1.legend( ( rmse_train[0], rmse_val[0]), ('Training','Test'),fontsize=15)\n",
    "\n",
    "ax2.tick_params(axis='both', which='major', labelsize=15)\n",
    "ax2.set_title('Loss',size=25)\n",
    "ax2.set_ylabel('Loss',size=20)\n",
    "ax2.set_xlabel('Epoch',size=20)\n",
    "loss_train=ax2.plot(history.history['loss'])\n",
    "loss_val=ax2.plot(history.history['val_loss'])\n",
    "\n",
    "ax2.legend( ( loss_train[0], loss_val[0]), ('Training','Test'),fontsize=15)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
