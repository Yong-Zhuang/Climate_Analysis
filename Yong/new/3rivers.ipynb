{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Notes\n",
    "Questions:\n",
    "* Train on all 3 rivers, or individual rivers? River transfer knowledge?\n",
    "* Which giver better result for 5 day forcast: seq to seq or rolling predictions?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pandas import read_csv\n",
    "from pandas import datetime\n",
    "from pandas import DataFrame\n",
    "#from statsmodels.tsa.arima_model import ARIMA\n",
    "import matplotlib.pylab as plt\n",
    "%matplotlib inline\n",
    "from matplotlib.pylab import rcParams\n",
    "rcParams['figure.figsize'] = 15, 6\n",
    "rcParams['axes.titlesize'] = 'xx-large'\n",
    "rcParams['axes.titleweight'] = 'bold'\n",
    "rcParams[\"legend.loc\"] = 'upper left'\n",
    "look = 15\n",
    "lead = 1 # 3, 5, 7, 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            Unnamed: 0  Q_-20  Q_-19  Q_-18  Q_-17  Q_-16  Q_-15  Q_-14  \\\n",
      "Date                                                                      \n",
      "1985-05-01         120  739.0  728.0  717.0  754.0  821.0  819.0  824.0   \n",
      "1985-05-02         121  728.0  717.0  754.0  821.0  819.0  824.0  814.0   \n",
      "1985-05-03         122  717.0  754.0  821.0  819.0  824.0  814.0  815.0   \n",
      "1985-05-04         123  754.0  821.0  819.0  824.0  814.0  815.0  803.0   \n",
      "1985-05-05         124  821.0  819.0  824.0  814.0  815.0  803.0  793.0   \n",
      "\n",
      "            Q_-13  Q_-12  ...     Q_-9   Q_-8   Q_-7   Q_-6   Q_-5   Q_-4  \\\n",
      "Date                      ...                                               \n",
      "1985-05-01  814.0  815.0  ...    800.0  805.0  813.0  824.0  829.0  829.0   \n",
      "1985-05-02  815.0  803.0  ...    805.0  813.0  824.0  829.0  829.0  852.0   \n",
      "1985-05-03  803.0  793.0  ...    813.0  824.0  829.0  829.0  852.0  810.0   \n",
      "1985-05-04  793.0  800.0  ...    824.0  829.0  829.0  852.0  810.0  756.0   \n",
      "1985-05-05  800.0  805.0  ...    829.0  829.0  852.0  810.0  756.0  751.0   \n",
      "\n",
      "             Q_-3   Q_-2   Q_-1    Q_0  \n",
      "Date                                    \n",
      "1985-05-01  852.0  810.0  756.0  751.0  \n",
      "1985-05-02  810.0  756.0  751.0  830.0  \n",
      "1985-05-03  756.0  751.0  830.0  903.0  \n",
      "1985-05-04  751.0  830.0  903.0  934.0  \n",
      "1985-05-05  830.0  903.0  934.0  952.0  \n",
      "\n",
      "[5 rows x 22 columns]\n",
      "End Qx.head()\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Q_1</th>\n",
       "      <th>Q_2</th>\n",
       "      <th>Q_3</th>\n",
       "      <th>Q_4</th>\n",
       "      <th>Q_5</th>\n",
       "      <th>Q_6</th>\n",
       "      <th>Q_7</th>\n",
       "      <th>Q_8</th>\n",
       "      <th>Q_9</th>\n",
       "      <th>Q_10</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1985-05-01</th>\n",
       "      <td>830.0</td>\n",
       "      <td>903.0</td>\n",
       "      <td>934.0</td>\n",
       "      <td>952.0</td>\n",
       "      <td>958.0</td>\n",
       "      <td>968.0</td>\n",
       "      <td>918.0</td>\n",
       "      <td>783.0</td>\n",
       "      <td>838.0</td>\n",
       "      <td>922.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1985-05-02</th>\n",
       "      <td>903.0</td>\n",
       "      <td>934.0</td>\n",
       "      <td>952.0</td>\n",
       "      <td>958.0</td>\n",
       "      <td>968.0</td>\n",
       "      <td>918.0</td>\n",
       "      <td>783.0</td>\n",
       "      <td>838.0</td>\n",
       "      <td>922.0</td>\n",
       "      <td>893.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1985-05-03</th>\n",
       "      <td>934.0</td>\n",
       "      <td>952.0</td>\n",
       "      <td>958.0</td>\n",
       "      <td>968.0</td>\n",
       "      <td>918.0</td>\n",
       "      <td>783.0</td>\n",
       "      <td>838.0</td>\n",
       "      <td>922.0</td>\n",
       "      <td>893.0</td>\n",
       "      <td>874.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1985-05-04</th>\n",
       "      <td>952.0</td>\n",
       "      <td>958.0</td>\n",
       "      <td>968.0</td>\n",
       "      <td>918.0</td>\n",
       "      <td>783.0</td>\n",
       "      <td>838.0</td>\n",
       "      <td>922.0</td>\n",
       "      <td>893.0</td>\n",
       "      <td>874.0</td>\n",
       "      <td>879.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1985-05-05</th>\n",
       "      <td>958.0</td>\n",
       "      <td>968.0</td>\n",
       "      <td>918.0</td>\n",
       "      <td>783.0</td>\n",
       "      <td>838.0</td>\n",
       "      <td>922.0</td>\n",
       "      <td>893.0</td>\n",
       "      <td>874.0</td>\n",
       "      <td>879.0</td>\n",
       "      <td>861.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              Q_1    Q_2    Q_3    Q_4    Q_5    Q_6    Q_7    Q_8    Q_9  \\\n",
       "Date                                                                        \n",
       "1985-05-01  830.0  903.0  934.0  952.0  958.0  968.0  918.0  783.0  838.0   \n",
       "1985-05-02  903.0  934.0  952.0  958.0  968.0  918.0  783.0  838.0  922.0   \n",
       "1985-05-03  934.0  952.0  958.0  968.0  918.0  783.0  838.0  922.0  893.0   \n",
       "1985-05-04  952.0  958.0  968.0  918.0  783.0  838.0  922.0  893.0  874.0   \n",
       "1985-05-05  958.0  968.0  918.0  783.0  838.0  922.0  893.0  874.0  879.0   \n",
       "\n",
       "             Q_10  \n",
       "Date               \n",
       "1985-05-01  922.0  \n",
       "1985-05-02  893.0  \n",
       "1985-05-03  874.0  \n",
       "1985-05-04  879.0  \n",
       "1985-05-05  861.0  "
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#1934-4-01  2018-07-09\n",
    "Qx = pd.read_csv('../../data/streamflw_precipitation/X_Ganges.csv', index_col=1,header=0,parse_dates=True) #Brahmaputra #Meghna\n",
    "print (Qx.head())\n",
    "print(\"End Qx.head()\")\n",
    "#print (Qx.index[-220:])\n",
    "idx = []\n",
    "for i in np.arange(1-look,1,1):\n",
    "    idx.append('Q_'+str(i))\n",
    "Qx = Qx.loc[:,idx]\n",
    "#print (Qx.head())\n",
    "Qy = pd.read_csv('../../data/streamflw_precipitation/Y_Ganges.csv', index_col=1,header=0,parse_dates=True)\n",
    "#print (Qy.head())\n",
    "idy = []\n",
    "for i in np.arange(lead,lead+10,1):\n",
    "    idy.append('Q_'+str(i))\n",
    "Qy = Qy.loc[:,idy]\n",
    "#print (Qy.head())\n",
    "\n",
    "Qy.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Processing\n",
    "Reshaping and Normalization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TODO: \n",
    "Filtering:\n",
    "1. Moving average (np.convolve, see 2nd answer https://stackoverflow.com/questions/13728392/moving-average-or-running-mean), could also add a convolution layer?\n",
    "2. Local Regression http://www.statsmodels.org/stable/generated/statsmodels.nonparametric.smoothers_lowess.lowess.html\n",
    "3. Savitzky-Golay filtering (scipy)\n",
    "4. Hamming Window Filtering (numpy and scipy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Unrolling Functions\n",
    "Impliment functions to unroll data windows into 1d, and reroll into 2d windows\n",
    "\n",
    "Having issues with indexing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                Q_1      Q_2      Q_3      Q_4      Q_5      Q_6      Q_7  \\\n",
      "Date                                                                        \n",
      "1985-05-01    830.0    903.0    934.0    952.0    958.0    968.0    918.0   \n",
      "1985-05-02    903.0    934.0    952.0    958.0    968.0    918.0    783.0   \n",
      "1985-05-03    934.0    952.0    958.0    968.0    918.0    783.0    838.0   \n",
      "1985-05-04    952.0    958.0    968.0    918.0    783.0    838.0    922.0   \n",
      "1985-05-05    958.0    968.0    918.0    783.0    838.0    922.0    893.0   \n",
      "1985-05-06    968.0    918.0    783.0    838.0    922.0    893.0    874.0   \n",
      "1985-05-07    918.0    783.0    838.0    922.0    893.0    874.0    879.0   \n",
      "1985-05-08    783.0    838.0    922.0    893.0    874.0    879.0    861.0   \n",
      "1985-05-09    838.0    922.0    893.0    874.0    879.0    861.0    832.0   \n",
      "1985-05-10    922.0    893.0    874.0    879.0    861.0    832.0    810.0   \n",
      "1985-05-11    893.0    874.0    879.0    861.0    832.0    810.0    787.0   \n",
      "1985-05-12    874.0    879.0    861.0    832.0    810.0    787.0    804.0   \n",
      "1985-05-13    879.0    861.0    832.0    810.0    787.0    804.0    792.0   \n",
      "1985-05-14    861.0    832.0    810.0    787.0    804.0    792.0    765.0   \n",
      "1985-05-15    832.0    810.0    787.0    804.0    792.0    765.0    784.0   \n",
      "1985-05-16    810.0    787.0    804.0    792.0    765.0    784.0    808.0   \n",
      "1985-05-17    787.0    804.0    792.0    765.0    784.0    808.0    823.0   \n",
      "1985-05-18    804.0    792.0    765.0    784.0    808.0    823.0    852.0   \n",
      "1985-05-19    792.0    765.0    784.0    808.0    823.0    852.0    901.0   \n",
      "1985-05-20    765.0    784.0    808.0    823.0    852.0    901.0    935.0   \n",
      "1985-05-21    784.0    808.0    823.0    852.0    901.0    935.0    977.0   \n",
      "1985-05-22    808.0    823.0    852.0    901.0    935.0    977.0   1030.0   \n",
      "1985-05-23    823.0    852.0    901.0    935.0    977.0   1030.0   1030.0   \n",
      "1985-05-24    852.0    901.0    935.0    977.0   1030.0   1030.0    995.0   \n",
      "1985-05-25    901.0    935.0    977.0   1030.0   1030.0    995.0    979.0   \n",
      "1985-05-26    935.0    977.0   1030.0   1030.0    995.0    979.0   1000.0   \n",
      "1985-05-27    977.0   1030.0   1030.0    995.0    979.0   1000.0   1110.0   \n",
      "1985-05-28   1030.0   1030.0    995.0    979.0   1000.0   1110.0   1260.0   \n",
      "1985-05-29   1030.0    995.0    979.0   1000.0   1110.0   1260.0   1530.0   \n",
      "1985-05-30    995.0    979.0   1000.0   1110.0   1260.0   1530.0   1670.0   \n",
      "...             ...      ...      ...      ...      ...      ...      ...   \n",
      "2016-09-01  50593.0  47103.0  42213.0  35055.0  29954.0  25841.0  24638.0   \n",
      "2016-09-02  47103.0  42213.0  35055.0  29954.0  25841.0  24638.0  24521.0   \n",
      "2016-09-03  42213.0  35055.0  29954.0  25841.0  24638.0  24521.0  24404.0   \n",
      "2016-09-04  35055.0  29954.0  25841.0  24638.0  24521.0  24404.0  24058.0   \n",
      "2016-09-05  29954.0  25841.0  24638.0  24521.0  24404.0  24058.0  23830.0   \n",
      "2016-09-06  25841.0  24638.0  24521.0  24404.0  24058.0  23830.0  23944.0   \n",
      "2016-09-07  24638.0  24521.0  24404.0  24058.0  23830.0  23944.0  24173.0   \n",
      "2016-09-08  24521.0  24404.0  24058.0  23830.0  23944.0  24173.0  24756.0   \n",
      "2016-09-09  24404.0  24058.0  23830.0  23944.0  24173.0  24756.0  24874.0   \n",
      "2016-09-10  24058.0  23830.0  23944.0  24173.0  24756.0  24874.0  23944.0   \n",
      "2016-09-11  23830.0  23944.0  24173.0  24756.0  24874.0  23944.0  22292.0   \n",
      "2016-09-12  23944.0  24173.0  24756.0  24874.0  23944.0  22292.0  21561.0   \n",
      "2016-09-13  24173.0  24756.0  24874.0  23944.0  22292.0  21561.0  21458.0   \n",
      "2016-09-14  24756.0  24874.0  23944.0  22292.0  21561.0  21458.0  21154.0   \n",
      "2016-09-15  24874.0  23944.0  22292.0  21561.0  21458.0  21154.0  20853.0   \n",
      "2016-09-16  23944.0  22292.0  21561.0  21458.0  21154.0  20853.0  20656.0   \n",
      "2016-09-17  22292.0  21561.0  21458.0  21154.0  20853.0  20656.0  20953.0   \n",
      "2016-09-18  21561.0  21458.0  21154.0  20853.0  20656.0  20953.0  21053.0   \n",
      "2016-09-19  21458.0  21154.0  20853.0  20656.0  20953.0  21053.0  21154.0   \n",
      "2016-09-20  21154.0  20853.0  20656.0  20953.0  21053.0  21154.0  21154.0   \n",
      "2016-09-21  20853.0  20656.0  20953.0  21053.0  21154.0  21154.0  20557.0   \n",
      "2016-09-22  20656.0  20953.0  21053.0  21154.0  21154.0  20557.0  20853.0   \n",
      "2016-09-23  20953.0  21053.0  21154.0  21154.0  20557.0  20853.0  22081.0   \n",
      "2016-09-24  21053.0  21154.0  21154.0  20557.0  20853.0  22081.0  22939.0   \n",
      "2016-09-25  21154.0  21154.0  20557.0  20853.0  22081.0  22939.0  23604.0   \n",
      "2016-09-26  21154.0  20557.0  20853.0  22081.0  22939.0  23604.0  24288.0   \n",
      "2016-09-27  20557.0  20853.0  22081.0  22939.0  23604.0  24288.0  25353.0   \n",
      "2016-09-28  20853.0  22081.0  22939.0  23604.0  24288.0  25353.0  26088.0   \n",
      "2016-09-29  22081.0  22939.0  23604.0  24288.0  25353.0  26088.0  25112.0   \n",
      "2016-09-30  22939.0  23604.0  24288.0  25353.0  26088.0  25112.0  23269.0   \n",
      "\n",
      "                Q_8      Q_9     Q_10  \n",
      "Date                                   \n",
      "1985-05-01    783.0    838.0    922.0  \n",
      "1985-05-02    838.0    922.0    893.0  \n",
      "1985-05-03    922.0    893.0    874.0  \n",
      "1985-05-04    893.0    874.0    879.0  \n",
      "1985-05-05    874.0    879.0    861.0  \n",
      "1985-05-06    879.0    861.0    832.0  \n",
      "1985-05-07    861.0    832.0    810.0  \n",
      "1985-05-08    832.0    810.0    787.0  \n",
      "1985-05-09    810.0    787.0    804.0  \n",
      "1985-05-10    787.0    804.0    792.0  \n",
      "1985-05-11    804.0    792.0    765.0  \n",
      "1985-05-12    792.0    765.0    784.0  \n",
      "1985-05-13    765.0    784.0    808.0  \n",
      "1985-05-14    784.0    808.0    823.0  \n",
      "1985-05-15    808.0    823.0    852.0  \n",
      "1985-05-16    823.0    852.0    901.0  \n",
      "1985-05-17    852.0    901.0    935.0  \n",
      "1985-05-18    901.0    935.0    977.0  \n",
      "1985-05-19    935.0    977.0   1030.0  \n",
      "1985-05-20    977.0   1030.0   1030.0  \n",
      "1985-05-21   1030.0   1030.0    995.0  \n",
      "1985-05-22   1030.0    995.0    979.0  \n",
      "1985-05-23    995.0    979.0   1000.0  \n",
      "1985-05-24    979.0   1000.0   1110.0  \n",
      "1985-05-25   1000.0   1110.0   1260.0  \n",
      "1985-05-26   1110.0   1260.0   1530.0  \n",
      "1985-05-27   1260.0   1530.0   1670.0  \n",
      "1985-05-28   1530.0   1670.0   1640.0  \n",
      "1985-05-29   1670.0   1640.0   1620.0  \n",
      "1985-05-30   1640.0   1620.0   1540.0  \n",
      "...             ...      ...      ...  \n",
      "2016-09-01  24521.0  24404.0  24058.0  \n",
      "2016-09-02  24404.0  24058.0  23830.0  \n",
      "2016-09-03  24058.0  23830.0  23944.0  \n",
      "2016-09-04  23830.0  23944.0  24173.0  \n",
      "2016-09-05  23944.0  24173.0  24756.0  \n",
      "2016-09-06  24173.0  24756.0  24874.0  \n",
      "2016-09-07  24756.0  24874.0  23944.0  \n",
      "2016-09-08  24874.0  23944.0  22292.0  \n",
      "2016-09-09  23944.0  22292.0  21561.0  \n",
      "2016-09-10  22292.0  21561.0  21458.0  \n",
      "2016-09-11  21561.0  21458.0  21154.0  \n",
      "2016-09-12  21458.0  21154.0  20853.0  \n",
      "2016-09-13  21154.0  20853.0  20656.0  \n",
      "2016-09-14  20853.0  20656.0  20953.0  \n",
      "2016-09-15  20656.0  20953.0  21053.0  \n",
      "2016-09-16  20953.0  21053.0  21154.0  \n",
      "2016-09-17  21053.0  21154.0  21154.0  \n",
      "2016-09-18  21154.0  21154.0  20557.0  \n",
      "2016-09-19  21154.0  20557.0  20853.0  \n",
      "2016-09-20  20557.0  20853.0  22081.0  \n",
      "2016-09-21  20853.0  22081.0  22939.0  \n",
      "2016-09-22  22081.0  22939.0  23604.0  \n",
      "2016-09-23  22939.0  23604.0  24288.0  \n",
      "2016-09-24  23604.0  24288.0  25353.0  \n",
      "2016-09-25  24288.0  25353.0  26088.0  \n",
      "2016-09-26  25353.0  26088.0  25112.0  \n",
      "2016-09-27  26088.0  25112.0  23269.0  \n",
      "2016-09-28  25112.0  23269.0  21255.0  \n",
      "2016-09-29  23269.0  21255.0  19323.0  \n",
      "2016-09-30  21255.0  19323.0  17734.0  \n",
      "\n",
      "[4896 rows x 10 columns]\n",
      ".............\n",
      ".............\n",
      ".............\n",
      "1985-05-01 00:00:00      922.0\n",
      "1985-05-02 00:00:00      893.0\n",
      "1985-05-03 00:00:00      874.0\n",
      "1985-05-04 00:00:00      879.0\n",
      "1985-05-05 00:00:00      861.0\n",
      "1985-05-06 00:00:00      832.0\n",
      "1985-05-07 00:00:00      810.0\n",
      "1985-05-08 00:00:00      787.0\n",
      "1985-05-09 00:00:00      804.0\n",
      "1985-05-10 00:00:00      792.0\n",
      "1985-05-11 00:00:00      765.0\n",
      "1985-05-12 00:00:00      784.0\n",
      "1985-05-13 00:00:00      808.0\n",
      "1985-05-14 00:00:00      823.0\n",
      "1985-05-15 00:00:00      852.0\n",
      "1985-05-16 00:00:00      901.0\n",
      "1985-05-17 00:00:00      935.0\n",
      "1985-05-18 00:00:00      977.0\n",
      "1985-05-19 00:00:00     1030.0\n",
      "1985-05-20 00:00:00     1030.0\n",
      "1985-05-21 00:00:00      995.0\n",
      "1985-05-22 00:00:00      979.0\n",
      "1985-05-23 00:00:00     1000.0\n",
      "1985-05-24 00:00:00     1110.0\n",
      "1985-05-25 00:00:00     1260.0\n",
      "1985-05-26 00:00:00     1530.0\n",
      "1985-05-27 00:00:00     1670.0\n",
      "1985-05-28 00:00:00     1640.0\n",
      "1985-05-29 00:00:00     1620.0\n",
      "1985-05-30 00:00:00     1540.0\n",
      "                        ...   \n",
      "2016-09-10 00:00:00    21458.0\n",
      "2016-09-11 00:00:00    21154.0\n",
      "2016-09-12 00:00:00    20853.0\n",
      "2016-09-13 00:00:00    20656.0\n",
      "2016-09-14 00:00:00    20953.0\n",
      "2016-09-15 00:00:00    21053.0\n",
      "2016-09-16 00:00:00    21154.0\n",
      "2016-09-17 00:00:00    21154.0\n",
      "2016-09-18 00:00:00    20557.0\n",
      "2016-09-19 00:00:00    20853.0\n",
      "2016-09-20 00:00:00    22081.0\n",
      "2016-09-21 00:00:00    22939.0\n",
      "2016-09-22 00:00:00    23604.0\n",
      "2016-09-23 00:00:00    24288.0\n",
      "2016-09-24 00:00:00    25353.0\n",
      "2016-09-25 00:00:00    26088.0\n",
      "2016-09-26 00:00:00    25112.0\n",
      "2016-09-27 00:00:00    23269.0\n",
      "2016-09-28 00:00:00    21255.0\n",
      "2016-09-29 00:00:00    19323.0\n",
      "Q_1                    22939.0\n",
      "Q_2                    23604.0\n",
      "Q_3                    24288.0\n",
      "Q_4                    25353.0\n",
      "Q_5                    26088.0\n",
      "Q_6                    25112.0\n",
      "Q_7                    23269.0\n",
      "Q_8                    21255.0\n",
      "Q_9                    19323.0\n",
      "Q_10                   17734.0\n",
      "Length: 4905, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# unroll data\n",
    "# FIX INDEXING! REMEMBER, DATES REFER TO Q_0, parse strings to ints if necessary! or unroll from last digit\n",
    "def unroll_x(df):\n",
    "    bulk = df.iloc[:-1,-1]\n",
    "    edgeCase = df.iloc[-1].T\n",
    "    unrolled = edgeCase.append(bulk)\n",
    "    return unrolled\n",
    "\n",
    "def unroll_y(df):\n",
    "    bulk = df.iloc[:-1,-1]\n",
    "    edgeCase = df.iloc[-1].T\n",
    "    unrolled = bulk.append(edgeCase)\n",
    "    return unrolled  \n",
    "\n",
    "print(Qy)\n",
    "print(\".............\")\n",
    "print(\".............\")\n",
    "print(\".............\")\n",
    "print(unroll_y(Qy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "               Q_-14     Q_-13     Q_-12     Q_-11     Q_-10      Q_-9  \\\n",
      "Date                                                                     \n",
      "1985-05-01  112121.0  112121.0  112121.0  112121.0  112121.0  112121.0   \n",
      "1985-05-02  112121.0  112121.0  112121.0  112121.0  112121.0  112121.0   \n",
      "\n",
      "                Q_-8      Q_-7      Q_-6      Q_-5      Q_-4      Q_-3  \\\n",
      "Date                                                                     \n",
      "1985-05-01  112121.0  112121.0  112121.0  112121.0  112121.0  112121.0   \n",
      "1985-05-02  112121.0  112121.0  112121.0  112121.0  112121.0  112121.0   \n",
      "\n",
      "                Q_-2      Q_-1       Q_0  \n",
      "Date                                      \n",
      "1985-05-01  112121.0  112121.0  112121.0  \n",
      "1985-05-02  112121.0  112121.0  112121.0  \n",
      "............\n",
      "............\n",
      "Q_-14    112120.0\n",
      "Q_-13    112120.0\n",
      "dtype: float64\n",
      "............\n",
      "............\n",
      "            Q_-14  Q_-13  Q_-12  Q_-11  Q_-10   Q_-9   Q_-8   Q_-7   Q_-6  \\\n",
      "Date                                                                        \n",
      "1985-05-01  False  False  False  False  False  False  False  False  False   \n",
      "1985-05-02  False  False  False  False  False  False  False  False  False   \n",
      "1985-05-03  False  False  False  False  False  False  False  False  False   \n",
      "1985-05-04  False  False  False  False  False  False  False  False  False   \n",
      "1985-05-05  False  False  False  False  False  False  False  False  False   \n",
      "1985-05-06  False  False  False  False  False  False  False  False  False   \n",
      "1985-05-07  False  False  False  False  False  False  False  False  False   \n",
      "1985-05-08  False  False  False  False  False  False  False  False   True   \n",
      "1985-05-09  False  False  False  False  False  False  False   True  False   \n",
      "1985-05-10  False  False  False  False  False  False   True  False   True   \n",
      "1985-05-11  False  False  False  False  False   True  False   True   True   \n",
      "1985-05-12  False  False  False  False   True  False   True   True   True   \n",
      "1985-05-13  False  False  False   True  False   True   True   True   True   \n",
      "1985-05-14  False  False   True  False   True   True   True   True   True   \n",
      "1985-05-15  False   True  False   True   True   True   True   True   True   \n",
      "1985-05-16   True  False   True   True   True   True   True   True   True   \n",
      "1985-05-17  False   True   True   True   True   True   True   True   True   \n",
      "1985-05-18   True   True   True   True   True   True   True   True   True   \n",
      "1985-05-19   True   True   True   True   True   True   True   True   True   \n",
      "1985-05-20   True   True   True   True   True   True   True   True   True   \n",
      "1985-05-21   True   True   True   True   True   True   True   True   True   \n",
      "1985-05-22   True   True   True   True   True   True   True   True   True   \n",
      "1985-05-23   True   True   True   True   True   True   True   True   True   \n",
      "1985-05-24   True   True   True   True   True   True   True   True  False   \n",
      "1985-05-25   True   True   True   True   True   True   True  False   True   \n",
      "1985-05-26   True   True   True   True   True   True  False   True   True   \n",
      "1985-05-27   True   True   True   True   True  False   True   True   True   \n",
      "1985-05-28   True   True   True   True  False   True   True   True   True   \n",
      "1985-05-29   True   True   True  False   True   True   True   True   True   \n",
      "1985-05-30   True   True  False   True   True   True   True   True   True   \n",
      "...           ...    ...    ...    ...    ...    ...    ...    ...    ...   \n",
      "2016-09-01  False  False  False  False  False  False  False  False  False   \n",
      "2016-09-02  False  False  False  False  False  False  False  False  False   \n",
      "2016-09-03  False  False  False  False  False  False  False  False  False   \n",
      "2016-09-04  False  False  False  False  False  False  False  False  False   \n",
      "2016-09-05  False  False  False  False  False  False  False  False  False   \n",
      "2016-09-06  False  False  False  False  False  False  False  False  False   \n",
      "2016-09-07  False  False  False  False  False  False  False  False  False   \n",
      "2016-09-08  False  False  False  False  False  False  False  False  False   \n",
      "2016-09-09  False  False  False  False  False  False  False  False  False   \n",
      "2016-09-10  False  False  False  False  False  False  False  False  False   \n",
      "2016-09-11  False  False  False  False  False  False  False  False  False   \n",
      "2016-09-12  False  False  False  False  False  False  False  False  False   \n",
      "2016-09-13  False  False  False  False  False  False  False  False  False   \n",
      "2016-09-14  False  False  False  False  False  False  False  False  False   \n",
      "2016-09-15  False  False  False  False  False  False  False  False  False   \n",
      "2016-09-16  False  False  False  False  False  False  False  False  False   \n",
      "2016-09-17  False  False  False  False  False  False  False  False  False   \n",
      "2016-09-18  False  False  False  False  False  False  False  False  False   \n",
      "2016-09-19  False  False  False  False  False  False  False  False  False   \n",
      "2016-09-20  False  False  False  False  False  False  False  False  False   \n",
      "2016-09-21  False  False  False  False  False  False  False  False  False   \n",
      "2016-09-22  False  False  False  False  False  False  False  False  False   \n",
      "2016-09-23  False  False  False  False  False  False  False  False  False   \n",
      "2016-09-24  False  False  False  False  False  False  False  False  False   \n",
      "2016-09-25  False  False  False  False  False  False  False  False  False   \n",
      "2016-09-26  False  False  False  False  False  False  False  False  False   \n",
      "2016-09-27  False  False  False  False  False  False  False  False  False   \n",
      "2016-09-28  False  False  False  False  False  False  False  False  False   \n",
      "2016-09-29  False  False  False  False  False  False  False  False  False   \n",
      "2016-09-30  False  False  False  False  False  False  False  False  False   \n",
      "\n",
      "             Q_-5   Q_-4   Q_-3   Q_-2   Q_-1    Q_0  \n",
      "Date                                                  \n",
      "1985-05-01  False  False  False  False  False  False  \n",
      "1985-05-02  False  False  False  False  False   True  \n",
      "1985-05-03  False  False  False  False   True  False  \n",
      "1985-05-04  False  False  False   True  False   True  \n",
      "1985-05-05  False  False   True  False   True   True  \n",
      "1985-05-06  False   True  False   True   True   True  \n",
      "1985-05-07   True  False   True   True   True   True  \n",
      "1985-05-08  False   True   True   True   True   True  \n",
      "1985-05-09   True   True   True   True   True   True  \n",
      "1985-05-10   True   True   True   True   True   True  \n",
      "1985-05-11   True   True   True   True   True   True  \n",
      "1985-05-12   True   True   True   True   True   True  \n",
      "1985-05-13   True   True   True   True   True   True  \n",
      "1985-05-14   True   True   True   True   True   True  \n",
      "1985-05-15   True   True   True   True   True   True  \n",
      "1985-05-16   True   True   True   True   True   True  \n",
      "1985-05-17   True   True   True   True   True   True  \n",
      "1985-05-18   True   True   True   True   True  False  \n",
      "1985-05-19   True   True   True   True  False   True  \n",
      "1985-05-20   True   True   True  False   True   True  \n",
      "1985-05-21   True   True  False   True   True   True  \n",
      "1985-05-22   True  False   True   True   True   True  \n",
      "1985-05-23  False   True   True   True   True   True  \n",
      "1985-05-24   True   True   True   True   True   True  \n",
      "1985-05-25   True   True   True   True   True   True  \n",
      "1985-05-26   True   True   True   True   True   True  \n",
      "1985-05-27   True   True   True   True   True   True  \n",
      "1985-05-28   True   True   True   True   True   True  \n",
      "1985-05-29   True   True   True   True   True   True  \n",
      "1985-05-30   True   True   True   True   True   True  \n",
      "...           ...    ...    ...    ...    ...    ...  \n",
      "2016-09-01  False  False  False  False  False  False  \n",
      "2016-09-02  False  False  False  False  False  False  \n",
      "2016-09-03  False  False  False  False  False  False  \n",
      "2016-09-04  False  False  False  False  False  False  \n",
      "2016-09-05  False  False  False  False  False  False  \n",
      "2016-09-06  False  False  False  False  False  False  \n",
      "2016-09-07  False  False  False  False  False  False  \n",
      "2016-09-08  False  False  False  False  False  False  \n",
      "2016-09-09  False  False  False  False  False  False  \n",
      "2016-09-10  False  False  False  False  False  False  \n",
      "2016-09-11  False  False  False  False  False  False  \n",
      "2016-09-12  False  False  False  False  False  False  \n",
      "2016-09-13  False  False  False  False  False  False  \n",
      "2016-09-14  False  False  False  False  False  False  \n",
      "2016-09-15  False  False  False  False  False  False  \n",
      "2016-09-16  False  False  False  False  False  False  \n",
      "2016-09-17  False  False  False  False  False  False  \n",
      "2016-09-18  False  False  False  False  False  False  \n",
      "2016-09-19  False  False  False  False  False  False  \n",
      "2016-09-20  False  False  False  False  False  False  \n",
      "2016-09-21  False  False  False  False  False  False  \n",
      "2016-09-22  False  False  False  False  False  False  \n",
      "2016-09-23  False  False  False  False  False  False  \n",
      "2016-09-24  False  False  False  False  False  False  \n",
      "2016-09-25  False  False  False  False  False  False  \n",
      "2016-09-26  False  False  False  False  False  False  \n",
      "2016-09-27  False  False  False  False  False  False  \n",
      "2016-09-28  False  False  False  False  False  False  \n",
      "2016-09-29  False  False  False  False  False  False  \n",
      "2016-09-30  False  False  False  False  False  False  \n",
      "\n",
      "[4896 rows x 15 columns]\n",
      "............\n",
      "............\n",
      "............\n",
      "............\n",
      "               Q_1     Q_2     Q_3     Q_4     Q_5     Q_6     Q_7     Q_8  \\\n",
      "Date                                                                         \n",
      "1985-05-01  3161.0  3053.0  3129.0  3225.0  3285.0  3401.0  3597.0  3733.0   \n",
      "1985-05-02  3053.0  3129.0  3225.0  3285.0  3401.0  3597.0  3733.0  3901.0   \n",
      "\n",
      "               Q_9    Q_10  \n",
      "Date                        \n",
      "1985-05-01  3901.0  4113.0  \n",
      "1985-05-02  4113.0  4113.0  \n",
      "............\n",
      "............\n",
      "1985-05-01    4113.0\n",
      "1985-05-02    4113.0\n",
      "dtype: float64\n",
      "............\n",
      "............\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              Q_1    Q_2    Q_3    Q_4    Q_5    Q_6    Q_7    Q_8    Q_9  \\\n",
      "Date                                                                        \n",
      "1985-05-01  False  False  False  False  False  False  False  False  False   \n",
      "1985-05-02  False  False  False  False  False  False  False  False  False   \n",
      "1985-05-03  False  False  False  False  False  False  False  False  False   \n",
      "1985-05-04  False  False  False  False  False  False  False  False  False   \n",
      "1985-05-05  False  False  False  False  False  False  False  False  False   \n",
      "1985-05-06  False  False  False  False  False  False  False  False  False   \n",
      "1985-05-07  False  False  False  False  False  False  False  False  False   \n",
      "1985-05-08  False  False  False  False  False  False  False  False  False   \n",
      "1985-05-09  False  False  False  False  False  False  False  False  False   \n",
      "1985-05-10  False  False  False  False  False  False  False  False  False   \n",
      "1985-05-11  False  False  False  False  False  False  False  False  False   \n",
      "1985-05-12  False  False  False  False  False  False  False  False  False   \n",
      "1985-05-13  False  False  False  False  False  False  False  False  False   \n",
      "1985-05-14  False  False  False  False  False  False  False  False  False   \n",
      "1985-05-15  False  False  False  False  False  False  False  False  False   \n",
      "1985-05-16  False  False  False  False  False  False  False  False  False   \n",
      "1985-05-17  False  False  False  False  False  False  False  False  False   \n",
      "1985-05-18  False  False  False  False  False  False  False  False  False   \n",
      "1985-05-19  False  False  False  False  False  False  False  False  False   \n",
      "1985-05-20  False  False  False  False  False  False  False  False  False   \n",
      "1985-05-21  False  False  False  False  False  False  False  False  False   \n",
      "1985-05-22  False  False  False  False  False  False  False  False  False   \n",
      "1985-05-23  False  False  False  False  False  False  False  False  False   \n",
      "1985-05-24  False  False  False  False  False  False  False  False  False   \n",
      "1985-05-25  False  False  False  False  False  False  False  False  False   \n",
      "1985-05-26  False  False  False  False  False  False  False  False  False   \n",
      "1985-05-27  False  False  False  False  False  False  False  False  False   \n",
      "1985-05-28  False  False  False  False  False  False  False  False  False   \n",
      "1985-05-29  False  False  False  False  False  False  False  False  False   \n",
      "1985-05-30  False  False  False  False  False  False  False  False  False   \n",
      "...           ...    ...    ...    ...    ...    ...    ...    ...    ...   \n",
      "2016-09-01  False  False  False  False  False  False  False  False  False   \n",
      "2016-09-02  False  False  False  False  False  False  False  False  False   \n",
      "2016-09-03  False  False  False  False  False  False  False  False  False   \n",
      "2016-09-04  False  False  False  False  False  False  False  False   True   \n",
      "2016-09-05  False  False  False  False  False  False  False   True   True   \n",
      "2016-09-06  False  False  False  False  False  False   True   True   True   \n",
      "2016-09-07  False  False  False  False  False   True   True   True   True   \n",
      "2016-09-08  False  False  False  False   True   True   True   True   True   \n",
      "2016-09-09  False  False  False   True   True   True   True   True   True   \n",
      "2016-09-10  False  False   True   True   True   True   True   True   True   \n",
      "2016-09-11  False   True   True   True   True   True   True   True   True   \n",
      "2016-09-12   True   True   True   True   True   True   True   True   True   \n",
      "2016-09-13   True   True   True   True   True   True   True   True  False   \n",
      "2016-09-14   True   True   True   True   True   True   True  False  False   \n",
      "2016-09-15   True   True   True   True   True   True  False  False  False   \n",
      "2016-09-16   True   True   True   True   True  False  False  False  False   \n",
      "2016-09-17   True   True   True   True  False  False  False  False  False   \n",
      "2016-09-18   True   True   True  False  False  False  False  False  False   \n",
      "2016-09-19   True   True  False  False  False  False  False  False  False   \n",
      "2016-09-20   True  False  False  False  False  False  False  False  False   \n",
      "2016-09-21  False  False  False  False  False  False  False  False  False   \n",
      "2016-09-22  False  False  False  False  False  False  False  False  False   \n",
      "2016-09-23  False  False  False  False  False  False  False  False  False   \n",
      "2016-09-24  False  False  False  False  False  False  False  False  False   \n",
      "2016-09-25  False  False  False  False  False  False  False  False  False   \n",
      "2016-09-26  False  False  False  False  False  False  False  False  False   \n",
      "2016-09-27  False  False  False  False  False  False  False  False  False   \n",
      "2016-09-28  False  False  False  False  False  False  False  False  False   \n",
      "2016-09-29  False  False  False  False  False  False  False  False  False   \n",
      "2016-09-30  False  False  False  False  False  False  False  False  False   \n",
      "\n",
      "             Q_10  \n",
      "Date               \n",
      "1985-05-01  False  \n",
      "1985-05-02  False  \n",
      "1985-05-03  False  \n",
      "1985-05-04  False  \n",
      "1985-05-05  False  \n",
      "1985-05-06  False  \n",
      "1985-05-07  False  \n",
      "1985-05-08  False  \n",
      "1985-05-09  False  \n",
      "1985-05-10  False  \n",
      "1985-05-11  False  \n",
      "1985-05-12  False  \n",
      "1985-05-13  False  \n",
      "1985-05-14  False  \n",
      "1985-05-15  False  \n",
      "1985-05-16  False  \n",
      "1985-05-17  False  \n",
      "1985-05-18  False  \n",
      "1985-05-19  False  \n",
      "1985-05-20  False  \n",
      "1985-05-21  False  \n",
      "1985-05-22  False  \n",
      "1985-05-23  False  \n",
      "1985-05-24  False  \n",
      "1985-05-25  False  \n",
      "1985-05-26  False  \n",
      "1985-05-27  False  \n",
      "1985-05-28  False  \n",
      "1985-05-29  False  \n",
      "1985-05-30  False  \n",
      "...           ...  \n",
      "2016-09-01  False  \n",
      "2016-09-02  False  \n",
      "2016-09-03   True  \n",
      "2016-09-04   True  \n",
      "2016-09-05   True  \n",
      "2016-09-06   True  \n",
      "2016-09-07   True  \n",
      "2016-09-08   True  \n",
      "2016-09-09   True  \n",
      "2016-09-10   True  \n",
      "2016-09-11   True  \n",
      "2016-09-12  False  \n",
      "2016-09-13  False  \n",
      "2016-09-14  False  \n",
      "2016-09-15  False  \n",
      "2016-09-16  False  \n",
      "2016-09-17  False  \n",
      "2016-09-18  False  \n",
      "2016-09-19  False  \n",
      "2016-09-20  False  \n",
      "2016-09-21  False  \n",
      "2016-09-22  False  \n",
      "2016-09-23  False  \n",
      "2016-09-24  False  \n",
      "2016-09-25  False  \n",
      "2016-09-26  False  \n",
      "2016-09-27  False  \n",
      "2016-09-28  False  \n",
      "2016-09-29  False  \n",
      "2016-09-30  False  \n",
      "\n",
      "[4896 rows x 10 columns]\n",
      "............\n",
      "............\n",
      "............\n",
      "............\n"
     ]
    }
   ],
   "source": [
    "#Can roll back up the original dataframes\n",
    "# Needs work\n",
    "def roll(df, original):\n",
    "    temp = original\n",
    "    temp = temp - original\n",
    "    original_columns = len(temp.columns)\n",
    "    total_rows = len(temp.index) - original_columns\n",
    "    for i in range(total_rows):\n",
    "        for j in range(original_columns):\n",
    "            temp.iloc[i][j] = df.iloc[i+j]\n",
    "    return temp\n",
    "        \n",
    "        \n",
    "#testing\n",
    "print(Qx.head(2))\n",
    "print(\"............\")\n",
    "print(\"............\")\n",
    "unrollx = unroll_x(Qx)\n",
    "print(unrollx.head(2))\n",
    "print(\"............\")\n",
    "print(\"............\")\n",
    "rollx = roll(unrollx, Qx)\n",
    "print(rollx.eq(Qx))\n",
    "print(\"............\")\n",
    "print(\"............\")\n",
    "print(\"............\")\n",
    "print(\"............\")\n",
    "print(Qy.head(2))\n",
    "print(\"............\")\n",
    "print(\"............\")\n",
    "unrolly = unroll_y(Qy)\n",
    "print(unrolly.head(2))\n",
    "print(\"............\")\n",
    "print(\"............\")\n",
    "rollx = roll(unrolly, Qy)\n",
    "print(rollx.eq(Qy))\n",
    "print(\"............\")\n",
    "print(\"............\")\n",
    "print(\"............\")\n",
    "print(\"............\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Filtering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Local Regression\n",
    "from statsmodels.nonparametric import smoothers_lowess"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "http://www.statsmodels.org/stable/generated/statsmodels.nonparametric.smoothers_lowess.lowess.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Savitzky-Golay and hamming\n",
    "from scipy import signal"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://docs.scipy.org/doc/scipy-0.16.1/reference/generated/scipy.signal.savgol_filter.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://docs.scipy.org/doc/scipy-0.16.1/reference/generated/scipy.signal.hamming.html#scipy.signal.hamming"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.swapaxes(Qx.values[np.newaxis], 0, 1)\n",
    "y = np.swapaxes(Qy.values[np.newaxis], 0, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4896, 1, 15)\n",
      "(4896, 1, 10)\n"
     ]
    }
   ],
   "source": [
    "print(X.shape)\n",
    "print(y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15\n"
     ]
    }
   ],
   "source": [
    "print(len(Qx.columns))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "\n",
    "from tensorflow.keras.layers import Dense, SimpleRNN, LSTM, Conv1D,Flatten\n",
    "\n",
    "from tensorflow.keras import initializers, regularizers\n",
    "\n",
    "from keras_pandas.Automater import Automater"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Params\n",
    "Default params for networks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Date\n",
       "1985-05-01    830.0\n",
       "1985-05-02    903.0\n",
       "1985-05-03    934.0\n",
       "1985-05-04    952.0\n",
       "1985-05-05    958.0\n",
       "Name: Q_1, dtype: float64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Rolling window of X\n",
    "rolling_window = len(Qx.columns)\n",
    "\n",
    "# of epochs\n",
    "numEpoch = 5\n",
    "\n",
    "# Which day are we predicting?\n",
    "y = Qy['Q_1']\n",
    "y.head().squeeze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "l2 = regularizers.l2\n",
    "bias = initializers.glorot_uniform(seed = 0)\n",
    "#kernal = "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense (Dense)                (None, 1, 10)             160       \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1, 10)             110       \n",
      "=================================================================\n",
      "Total params: 270\n",
      "Trainable params: 270\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "def initDense():\n",
    "    # Initialize network as sequential\n",
    "    model = Sequential()\n",
    "    \n",
    "    # Add reccurant layer\n",
    "    model.add(Dense(10,\n",
    "                        input_shape = (1, rolling_window),))\n",
    "    \n",
    "    # Add dense layer\n",
    "    model.add(Dense(1,))\n",
    "    \n",
    "    #return model\n",
    "    return model\n",
    "    \n",
    "initDense().summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "simple_rnn (SimpleRNN)       (None, 10)                260       \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 1)                 11        \n",
      "=================================================================\n",
      "Total params: 271\n",
      "Trainable params: 271\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "def initRNN():\n",
    "    # Initialize network as sequential\n",
    "    model = Sequential()\n",
    "        \n",
    "    # Add reccurant layer\n",
    "    model.add(SimpleRNN(10,\n",
    "                        input_shape = (1, rolling_window),))\n",
    "    \n",
    "    # Syncronize with input shape    \n",
    "    #model.add(Flatten())\n",
    "\n",
    "    \n",
    "    # Add dense layer\n",
    "    model.add(Dense(1))\n",
    "    \n",
    "    #return model\n",
    "    return model\n",
    "    \n",
    "initRNN().summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm (LSTM)                  (None, 10)                1040      \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 1)                 11        \n",
      "=================================================================\n",
      "Total params: 1,051\n",
      "Trainable params: 1,051\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "def initLSTM():\n",
    "    # Initialize network as sequential\n",
    "    model = Sequential()\n",
    "    \n",
    "    # Add reccurant LSTM layer\n",
    "    model.add(LSTM(10,\n",
    "                        input_shape = (1, rolling_window),))\n",
    "    \n",
    "    # Add dense layer\n",
    "    model.add(Dense(1,))\n",
    "    \n",
    "    #return model\n",
    "    return model\n",
    "    \n",
    "initLSTM().summary() "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CNN\n",
    "Issues:\n",
    "Input shape dimensionality"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Negative dimension size caused by subtracting 2 from 1 for 'conv1d/conv1d/Conv2D' (op: 'Conv2D') with input shapes: [?,1,1,15], [1,2,15,10].",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m\u001b[0m",
      "\u001b[0;31mValueError\u001b[0mTraceback (most recent call last)",
      "\u001b[0;32m<ipython-input-36-868afcccb2ee>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m \u001b[0minitConv1D\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msummary\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-36-868afcccb2ee>\u001b[0m in \u001b[0;36minitConv1D\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0;31m# Add reccurant LSTM layer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m     \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mConv1D\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilters\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkernel_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_shape\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrolling_window\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m     \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mFlatten\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0;31m# Add dense layer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/checkpointable/base.pyc\u001b[0m in \u001b[0;36m_method_wrapper\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    424\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_setattr_tracking\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mFalse\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    425\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 426\u001b[0;31m       \u001b[0mmethod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    427\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    428\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_setattr_tracking\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mprevious_value\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/tensorflow/python/keras/engine/sequential.pyc\u001b[0m in \u001b[0;36madd\u001b[0;34m(self, layer)\u001b[0m\n\u001b[1;32m    157\u001b[0m           \u001b[0;31m# and create the node connecting the current layer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    158\u001b[0m           \u001b[0;31m# to the input layer we just created.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 159\u001b[0;31m           \u001b[0mlayer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    160\u001b[0m           \u001b[0mset_inputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    161\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/tensorflow/python/keras/engine/base_layer.pyc\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs, *args, **kwargs)\u001b[0m\n\u001b[1;32m    767\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    768\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0min_deferred_mode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 769\u001b[0;31m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    770\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0moutputs\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    771\u001b[0m           raise ValueError('A layer\\'s `call` method should return a Tensor '\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/tensorflow/python/keras/layers/convolutional.pyc\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m    184\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    185\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mcall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 186\u001b[0;31m     \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_convolution_op\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkernel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    187\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    188\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muse_bias\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/tensorflow/python/ops/nn_ops.pyc\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inp, filter)\u001b[0m\n\u001b[1;32m    867\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    868\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfilter\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=redefined-builtin\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 869\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv_op\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfilter\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    870\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    871\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/tensorflow/python/ops/nn_ops.pyc\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inp, filter)\u001b[0m\n\u001b[1;32m    519\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    520\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfilter\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=redefined-builtin\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 521\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfilter\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    522\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    523\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/tensorflow/python/ops/nn_ops.pyc\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inp, filter)\u001b[0m\n\u001b[1;32m    203\u001b[0m         \u001b[0mpadding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpadding\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    204\u001b[0m         \u001b[0mdata_format\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata_format\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 205\u001b[0;31m         name=self.name)\n\u001b[0m\u001b[1;32m    206\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    207\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/tensorflow/python/ops/nn_ops.pyc\u001b[0m in \u001b[0;36m_conv1d\u001b[0;34m(self, input, filter, strides, padding, data_format, name)\u001b[0m\n\u001b[1;32m    192\u001b[0m         \u001b[0mpadding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpadding\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    193\u001b[0m         \u001b[0mdata_format\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdata_format\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 194\u001b[0;31m         name=name)\n\u001b[0m\u001b[1;32m    195\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    196\u001b[0m   \u001b[0;31m# pylint: enable=redefined-builtin\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/tensorflow/python/util/deprecation.pyc\u001b[0m in \u001b[0;36mnew_func\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    551\u001b[0m                   \u001b[0mfunc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__module__\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0marg_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0marg_value\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'in a future version'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    552\u001b[0m                   if date is None else ('after %s' % date), instructions)\n\u001b[0;32m--> 553\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    554\u001b[0m     return tf_decorator.make_decorator(func, new_func, 'deprecated',\n\u001b[1;32m    555\u001b[0m                                        _add_deprecated_arg_notice_to_docstring(\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/tensorflow/python/util/deprecation.pyc\u001b[0m in \u001b[0;36mnew_func\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    551\u001b[0m                   \u001b[0mfunc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__module__\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0marg_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0marg_value\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'in a future version'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    552\u001b[0m                   if date is None else ('after %s' % date), instructions)\n\u001b[0;32m--> 553\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    554\u001b[0m     return tf_decorator.make_decorator(func, new_func, 'deprecated',\n\u001b[1;32m    555\u001b[0m                                        _add_deprecated_arg_notice_to_docstring(\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/tensorflow/python/ops/nn_ops.pyc\u001b[0m in \u001b[0;36mconv1d\u001b[0;34m(value, filters, stride, padding, use_cudnn_on_gpu, data_format, name)\u001b[0m\n\u001b[1;32m   2493\u001b[0m         \u001b[0mpadding\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2494\u001b[0m         \u001b[0muse_cudnn_on_gpu\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0muse_cudnn_on_gpu\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2495\u001b[0;31m         data_format=data_format)\n\u001b[0m\u001b[1;32m   2496\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0marray_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mspatial_start_dim\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2497\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/tensorflow/python/ops/gen_nn_ops.pyc\u001b[0m in \u001b[0;36mconv2d\u001b[0;34m(input, filter, strides, padding, use_cudnn_on_gpu, data_format, dilations, name)\u001b[0m\n\u001b[1;32m    955\u001b[0m         \u001b[0;34m\"Conv2D\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfilter\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfilter\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstrides\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstrides\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    956\u001b[0m         \u001b[0mpadding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpadding\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0muse_cudnn_on_gpu\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0muse_cudnn_on_gpu\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 957\u001b[0;31m         data_format=data_format, dilations=dilations, name=name)\n\u001b[0m\u001b[1;32m    958\u001b[0m     \u001b[0m_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_op\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    959\u001b[0m     \u001b[0m_inputs_flat\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_op\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/tensorflow/python/framework/op_def_library.pyc\u001b[0m in \u001b[0;36m_apply_op_helper\u001b[0;34m(self, op_type_name, name, **keywords)\u001b[0m\n\u001b[1;32m    785\u001b[0m         op = g.create_op(op_type_name, inputs, output_types, name=scope,\n\u001b[1;32m    786\u001b[0m                          \u001b[0minput_types\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minput_types\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattr_protos\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 787\u001b[0;31m                          op_def=op_def)\n\u001b[0m\u001b[1;32m    788\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0moutput_structure\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mop_def\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_stateful\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    789\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/tensorflow/python/util/deprecation.pyc\u001b[0m in \u001b[0;36mnew_func\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    486\u001b[0m                 \u001b[0;34m'in a future version'\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mdate\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m'after %s'\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mdate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    487\u001b[0m                 instructions)\n\u001b[0;32m--> 488\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    489\u001b[0m     return tf_decorator.make_decorator(func, new_func, 'deprecated',\n\u001b[1;32m    490\u001b[0m                                        _add_deprecated_arg_notice_to_docstring(\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/tensorflow/python/framework/ops.pyc\u001b[0m in \u001b[0;36mcreate_op\u001b[0;34m(***failed resolving arguments***)\u001b[0m\n\u001b[1;32m   3270\u001b[0m           \u001b[0minput_types\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minput_types\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3271\u001b[0m           \u001b[0moriginal_op\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_default_original_op\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3272\u001b[0;31m           op_def=op_def)\n\u001b[0m\u001b[1;32m   3273\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_create_op_helper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mret\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcompute_device\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcompute_device\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3274\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mret\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/tensorflow/python/framework/ops.pyc\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, node_def, g, inputs, output_types, control_inputs, input_types, original_op, op_def)\u001b[0m\n\u001b[1;32m   1788\u001b[0m           op_def, inputs, node_def.attr)\n\u001b[1;32m   1789\u001b[0m       self._c_op = _create_c_op(self._graph, node_def, grouped_inputs,\n\u001b[0;32m-> 1790\u001b[0;31m                                 control_input_ops)\n\u001b[0m\u001b[1;32m   1791\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1792\u001b[0m     \u001b[0;31m# Initialize self._outputs.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/tensorflow/python/framework/ops.pyc\u001b[0m in \u001b[0;36m_create_c_op\u001b[0;34m(graph, node_def, inputs, control_inputs)\u001b[0m\n\u001b[1;32m   1627\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mInvalidArgumentError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1628\u001b[0m     \u001b[0;31m# Convert to ValueError for backwards compatibility.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1629\u001b[0;31m     \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1630\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1631\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0mc_op\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Negative dimension size caused by subtracting 2 from 1 for 'conv1d/conv1d/Conv2D' (op: 'Conv2D') with input shapes: [?,1,1,15], [1,2,15,10]."
     ]
    }
   ],
   "source": [
    "def initCNN():\n",
    "    # Initialize network as sequential\n",
    "    model = Sequential()\n",
    "    \n",
    "    # Add reccurant LSTM layer\n",
    "    model.add(Conv1D(filters = 10, kernel_size = 2, input_shape = (1, rolling_window),))\n",
    "    model.add(Flatten())\n",
    "    # Add dense layer\n",
    "    model.add(Dense(1,))\n",
    "    \n",
    "    #return model\n",
    "    return model\n",
    "    \n",
    "initConv1D().summary() "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Arima"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from statsmodels.tsa.arima_model import ARIMA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[  824.   814.   815. ...   810.   756.   751.]\n",
      " [  814.   815.   803. ...   756.   751.   830.]\n",
      " [  815.   803.   793. ...   751.   830.   903.]\n",
      " ...\n",
      " [24173. 24756. 24874. ... 21154. 21154. 20557.]\n",
      " [24756. 24874. 23944. ... 21154. 20557. 20853.]\n",
      " [24874. 23944. 22292. ... 20557. 20853. 22081.]]\n",
      "(4896, 15)\n",
      "              Q_-14    Q_-13    Q_-12    Q_-11    Q_-10     Q_-9     Q_-8  \\\n",
      "Date                                                                        \n",
      "1985-05-01    824.0    814.0    815.0    803.0    793.0    800.0    805.0   \n",
      "1985-05-02    814.0    815.0    803.0    793.0    800.0    805.0    813.0   \n",
      "1985-05-03    815.0    803.0    793.0    800.0    805.0    813.0    824.0   \n",
      "1985-05-04    803.0    793.0    800.0    805.0    813.0    824.0    829.0   \n",
      "1985-05-05    793.0    800.0    805.0    813.0    824.0    829.0    829.0   \n",
      "1985-05-06    800.0    805.0    813.0    824.0    829.0    829.0    852.0   \n",
      "1985-05-07    805.0    813.0    824.0    829.0    829.0    852.0    810.0   \n",
      "1985-05-08    813.0    824.0    829.0    829.0    852.0    810.0    756.0   \n",
      "1985-05-09    824.0    829.0    829.0    852.0    810.0    756.0    751.0   \n",
      "1985-05-10    829.0    829.0    852.0    810.0    756.0    751.0    830.0   \n",
      "1985-05-11    829.0    852.0    810.0    756.0    751.0    830.0    903.0   \n",
      "1985-05-12    852.0    810.0    756.0    751.0    830.0    903.0    934.0   \n",
      "1985-05-13    810.0    756.0    751.0    830.0    903.0    934.0    952.0   \n",
      "1985-05-14    756.0    751.0    830.0    903.0    934.0    952.0    958.0   \n",
      "1985-05-15    751.0    830.0    903.0    934.0    952.0    958.0    968.0   \n",
      "1985-05-16    830.0    903.0    934.0    952.0    958.0    968.0    918.0   \n",
      "1985-05-17    903.0    934.0    952.0    958.0    968.0    918.0    783.0   \n",
      "1985-05-18    934.0    952.0    958.0    968.0    918.0    783.0    838.0   \n",
      "1985-05-19    952.0    958.0    968.0    918.0    783.0    838.0    922.0   \n",
      "1985-05-20    958.0    968.0    918.0    783.0    838.0    922.0    893.0   \n",
      "1985-05-21    968.0    918.0    783.0    838.0    922.0    893.0    874.0   \n",
      "1985-05-22    918.0    783.0    838.0    922.0    893.0    874.0    879.0   \n",
      "1985-05-23    783.0    838.0    922.0    893.0    874.0    879.0    861.0   \n",
      "1985-05-24    838.0    922.0    893.0    874.0    879.0    861.0    832.0   \n",
      "1985-05-25    922.0    893.0    874.0    879.0    861.0    832.0    810.0   \n",
      "1985-05-26    893.0    874.0    879.0    861.0    832.0    810.0    787.0   \n",
      "1985-05-27    874.0    879.0    861.0    832.0    810.0    787.0    804.0   \n",
      "1985-05-28    879.0    861.0    832.0    810.0    787.0    804.0    792.0   \n",
      "1985-05-29    861.0    832.0    810.0    787.0    804.0    792.0    765.0   \n",
      "1985-05-30    832.0    810.0    787.0    804.0    792.0    765.0    784.0   \n",
      "...             ...      ...      ...      ...      ...      ...      ...   \n",
      "2016-09-01  37652.0  39302.0  39678.0  41416.0  43026.0  44698.0  47103.0   \n",
      "2016-09-02  39302.0  39678.0  41416.0  43026.0  44698.0  47103.0  49638.0   \n",
      "2016-09-03  39678.0  41416.0  43026.0  44698.0  47103.0  49638.0  52559.0   \n",
      "2016-09-04  41416.0  43026.0  44698.0  47103.0  49638.0  52559.0  55124.0   \n",
      "2016-09-05  43026.0  44698.0  47103.0  49638.0  52559.0  55124.0  55652.0   \n",
      "2016-09-06  44698.0  47103.0  49638.0  52559.0  55124.0  55652.0  54862.0   \n",
      "2016-09-07  47103.0  49638.0  52559.0  55124.0  55652.0  54862.0  54341.0   \n",
      "2016-09-08  49638.0  52559.0  55124.0  55652.0  54862.0  54341.0  53570.0   \n",
      "2016-09-09  52559.0  55124.0  55652.0  54862.0  54341.0  53570.0  52810.0   \n",
      "2016-09-10  55124.0  55652.0  54862.0  54341.0  53570.0  52810.0  50593.0   \n",
      "2016-09-11  55652.0  54862.0  54341.0  53570.0  52810.0  50593.0  47103.0   \n",
      "2016-09-12  54862.0  54341.0  53570.0  52810.0  50593.0  47103.0  42213.0   \n",
      "2016-09-13  54341.0  53570.0  52810.0  50593.0  47103.0  42213.0  35055.0   \n",
      "2016-09-14  53570.0  52810.0  50593.0  47103.0  42213.0  35055.0  29954.0   \n",
      "2016-09-15  52810.0  50593.0  47103.0  42213.0  35055.0  29954.0  25841.0   \n",
      "2016-09-16  50593.0  47103.0  42213.0  35055.0  29954.0  25841.0  24638.0   \n",
      "2016-09-17  47103.0  42213.0  35055.0  29954.0  25841.0  24638.0  24521.0   \n",
      "2016-09-18  42213.0  35055.0  29954.0  25841.0  24638.0  24521.0  24404.0   \n",
      "2016-09-19  35055.0  29954.0  25841.0  24638.0  24521.0  24404.0  24058.0   \n",
      "2016-09-20  29954.0  25841.0  24638.0  24521.0  24404.0  24058.0  23830.0   \n",
      "2016-09-21  25841.0  24638.0  24521.0  24404.0  24058.0  23830.0  23944.0   \n",
      "2016-09-22  24638.0  24521.0  24404.0  24058.0  23830.0  23944.0  24173.0   \n",
      "2016-09-23  24521.0  24404.0  24058.0  23830.0  23944.0  24173.0  24756.0   \n",
      "2016-09-24  24404.0  24058.0  23830.0  23944.0  24173.0  24756.0  24874.0   \n",
      "2016-09-25  24058.0  23830.0  23944.0  24173.0  24756.0  24874.0  23944.0   \n",
      "2016-09-26  23830.0  23944.0  24173.0  24756.0  24874.0  23944.0  22292.0   \n",
      "2016-09-27  23944.0  24173.0  24756.0  24874.0  23944.0  22292.0  21561.0   \n",
      "2016-09-28  24173.0  24756.0  24874.0  23944.0  22292.0  21561.0  21458.0   \n",
      "2016-09-29  24756.0  24874.0  23944.0  22292.0  21561.0  21458.0  21154.0   \n",
      "2016-09-30  24874.0  23944.0  22292.0  21561.0  21458.0  21154.0  20853.0   \n",
      "\n",
      "               Q_-7     Q_-6     Q_-5     Q_-4     Q_-3     Q_-2     Q_-1  \\\n",
      "Date                                                                        \n",
      "1985-05-01    813.0    824.0    829.0    829.0    852.0    810.0    756.0   \n",
      "1985-05-02    824.0    829.0    829.0    852.0    810.0    756.0    751.0   \n",
      "1985-05-03    829.0    829.0    852.0    810.0    756.0    751.0    830.0   \n",
      "1985-05-04    829.0    852.0    810.0    756.0    751.0    830.0    903.0   \n",
      "1985-05-05    852.0    810.0    756.0    751.0    830.0    903.0    934.0   \n",
      "1985-05-06    810.0    756.0    751.0    830.0    903.0    934.0    952.0   \n",
      "1985-05-07    756.0    751.0    830.0    903.0    934.0    952.0    958.0   \n",
      "1985-05-08    751.0    830.0    903.0    934.0    952.0    958.0    968.0   \n",
      "1985-05-09    830.0    903.0    934.0    952.0    958.0    968.0    918.0   \n",
      "1985-05-10    903.0    934.0    952.0    958.0    968.0    918.0    783.0   \n",
      "1985-05-11    934.0    952.0    958.0    968.0    918.0    783.0    838.0   \n",
      "1985-05-12    952.0    958.0    968.0    918.0    783.0    838.0    922.0   \n",
      "1985-05-13    958.0    968.0    918.0    783.0    838.0    922.0    893.0   \n",
      "1985-05-14    968.0    918.0    783.0    838.0    922.0    893.0    874.0   \n",
      "1985-05-15    918.0    783.0    838.0    922.0    893.0    874.0    879.0   \n",
      "1985-05-16    783.0    838.0    922.0    893.0    874.0    879.0    861.0   \n",
      "1985-05-17    838.0    922.0    893.0    874.0    879.0    861.0    832.0   \n",
      "1985-05-18    922.0    893.0    874.0    879.0    861.0    832.0    810.0   \n",
      "1985-05-19    893.0    874.0    879.0    861.0    832.0    810.0    787.0   \n",
      "1985-05-20    874.0    879.0    861.0    832.0    810.0    787.0    804.0   \n",
      "1985-05-21    879.0    861.0    832.0    810.0    787.0    804.0    792.0   \n",
      "1985-05-22    861.0    832.0    810.0    787.0    804.0    792.0    765.0   \n",
      "1985-05-23    832.0    810.0    787.0    804.0    792.0    765.0    784.0   \n",
      "1985-05-24    810.0    787.0    804.0    792.0    765.0    784.0    808.0   \n",
      "1985-05-25    787.0    804.0    792.0    765.0    784.0    808.0    823.0   \n",
      "1985-05-26    804.0    792.0    765.0    784.0    808.0    823.0    852.0   \n",
      "1985-05-27    792.0    765.0    784.0    808.0    823.0    852.0    901.0   \n",
      "1985-05-28    765.0    784.0    808.0    823.0    852.0    901.0    935.0   \n",
      "1985-05-29    784.0    808.0    823.0    852.0    901.0    935.0    977.0   \n",
      "1985-05-30    808.0    823.0    852.0    901.0    935.0    977.0   1030.0   \n",
      "...             ...      ...      ...      ...      ...      ...      ...   \n",
      "2016-09-01  49638.0  52559.0  55124.0  55652.0  54862.0  54341.0  53570.0   \n",
      "2016-09-02  52559.0  55124.0  55652.0  54862.0  54341.0  53570.0  52810.0   \n",
      "2016-09-03  55124.0  55652.0  54862.0  54341.0  53570.0  52810.0  50593.0   \n",
      "2016-09-04  55652.0  54862.0  54341.0  53570.0  52810.0  50593.0  47103.0   \n",
      "2016-09-05  54862.0  54341.0  53570.0  52810.0  50593.0  47103.0  42213.0   \n",
      "2016-09-06  54341.0  53570.0  52810.0  50593.0  47103.0  42213.0  35055.0   \n",
      "2016-09-07  53570.0  52810.0  50593.0  47103.0  42213.0  35055.0  29954.0   \n",
      "2016-09-08  52810.0  50593.0  47103.0  42213.0  35055.0  29954.0  25841.0   \n",
      "2016-09-09  50593.0  47103.0  42213.0  35055.0  29954.0  25841.0  24638.0   \n",
      "2016-09-10  47103.0  42213.0  35055.0  29954.0  25841.0  24638.0  24521.0   \n",
      "2016-09-11  42213.0  35055.0  29954.0  25841.0  24638.0  24521.0  24404.0   \n",
      "2016-09-12  35055.0  29954.0  25841.0  24638.0  24521.0  24404.0  24058.0   \n",
      "2016-09-13  29954.0  25841.0  24638.0  24521.0  24404.0  24058.0  23830.0   \n",
      "2016-09-14  25841.0  24638.0  24521.0  24404.0  24058.0  23830.0  23944.0   \n",
      "2016-09-15  24638.0  24521.0  24404.0  24058.0  23830.0  23944.0  24173.0   \n",
      "2016-09-16  24521.0  24404.0  24058.0  23830.0  23944.0  24173.0  24756.0   \n",
      "2016-09-17  24404.0  24058.0  23830.0  23944.0  24173.0  24756.0  24874.0   \n",
      "2016-09-18  24058.0  23830.0  23944.0  24173.0  24756.0  24874.0  23944.0   \n",
      "2016-09-19  23830.0  23944.0  24173.0  24756.0  24874.0  23944.0  22292.0   \n",
      "2016-09-20  23944.0  24173.0  24756.0  24874.0  23944.0  22292.0  21561.0   \n",
      "2016-09-21  24173.0  24756.0  24874.0  23944.0  22292.0  21561.0  21458.0   \n",
      "2016-09-22  24756.0  24874.0  23944.0  22292.0  21561.0  21458.0  21154.0   \n",
      "2016-09-23  24874.0  23944.0  22292.0  21561.0  21458.0  21154.0  20853.0   \n",
      "2016-09-24  23944.0  22292.0  21561.0  21458.0  21154.0  20853.0  20656.0   \n",
      "2016-09-25  22292.0  21561.0  21458.0  21154.0  20853.0  20656.0  20953.0   \n",
      "2016-09-26  21561.0  21458.0  21154.0  20853.0  20656.0  20953.0  21053.0   \n",
      "2016-09-27  21458.0  21154.0  20853.0  20656.0  20953.0  21053.0  21154.0   \n",
      "2016-09-28  21154.0  20853.0  20656.0  20953.0  21053.0  21154.0  21154.0   \n",
      "2016-09-29  20853.0  20656.0  20953.0  21053.0  21154.0  21154.0  20557.0   \n",
      "2016-09-30  20656.0  20953.0  21053.0  21154.0  21154.0  20557.0  20853.0   \n",
      "\n",
      "                Q_0  \n",
      "Date                 \n",
      "1985-05-01    751.0  \n",
      "1985-05-02    830.0  \n",
      "1985-05-03    903.0  \n",
      "1985-05-04    934.0  \n",
      "1985-05-05    952.0  \n",
      "1985-05-06    958.0  \n",
      "1985-05-07    968.0  \n",
      "1985-05-08    918.0  \n",
      "1985-05-09    783.0  \n",
      "1985-05-10    838.0  \n",
      "1985-05-11    922.0  \n",
      "1985-05-12    893.0  \n",
      "1985-05-13    874.0  \n",
      "1985-05-14    879.0  \n",
      "1985-05-15    861.0  \n",
      "1985-05-16    832.0  \n",
      "1985-05-17    810.0  \n",
      "1985-05-18    787.0  \n",
      "1985-05-19    804.0  \n",
      "1985-05-20    792.0  \n",
      "1985-05-21    765.0  \n",
      "1985-05-22    784.0  \n",
      "1985-05-23    808.0  \n",
      "1985-05-24    823.0  \n",
      "1985-05-25    852.0  \n",
      "1985-05-26    901.0  \n",
      "1985-05-27    935.0  \n",
      "1985-05-28    977.0  \n",
      "1985-05-29   1030.0  \n",
      "1985-05-30   1030.0  \n",
      "...             ...  \n",
      "2016-09-01  52810.0  \n",
      "2016-09-02  50593.0  \n",
      "2016-09-03  47103.0  \n",
      "2016-09-04  42213.0  \n",
      "2016-09-05  35055.0  \n",
      "2016-09-06  29954.0  \n",
      "2016-09-07  25841.0  \n",
      "2016-09-08  24638.0  \n",
      "2016-09-09  24521.0  \n",
      "2016-09-10  24404.0  \n",
      "2016-09-11  24058.0  \n",
      "2016-09-12  23830.0  \n",
      "2016-09-13  23944.0  \n",
      "2016-09-14  24173.0  \n",
      "2016-09-15  24756.0  \n",
      "2016-09-16  24874.0  \n",
      "2016-09-17  23944.0  \n",
      "2016-09-18  22292.0  \n",
      "2016-09-19  21561.0  \n",
      "2016-09-20  21458.0  \n",
      "2016-09-21  21154.0  \n",
      "2016-09-22  20853.0  \n",
      "2016-09-23  20656.0  \n",
      "2016-09-24  20953.0  \n",
      "2016-09-25  21053.0  \n",
      "2016-09-26  21154.0  \n",
      "2016-09-27  21154.0  \n",
      "2016-09-28  20557.0  \n",
      "2016-09-29  20853.0  \n",
      "2016-09-30  22081.0  \n",
      "\n",
      "[4896 rows x 15 columns]\n",
      "(4896, 15)\n"
     ]
    }
   ],
   "source": [
    "QxV = Qx.values\n",
    "print(QxV)\n",
    "print(QxV.shape)\n",
    "print(Qx)\n",
    "print(Qx.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TODO:\n",
    "MAKE EACH YEAR A BATCH!!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(None, 1, 15)\n",
      "Train on 4406 samples, validate on 490 samples\n",
      "Epoch 1/5\n",
      " - 8s - loss: 695060179.7410 - val_loss: 459768013.7114\n",
      "Epoch 2/5\n",
      " - 8s - loss: 693672543.4711 - val_loss: 458677493.7848\n",
      "Epoch 3/5\n",
      " - 9s - loss: 692274064.1454 - val_loss: 457584966.2370\n",
      "Epoch 4/5\n",
      " - 9s - loss: 690894364.6380 - val_loss: 456505394.1075\n",
      "Epoch 5/5\n",
      " - 9s - loss: 689512834.2005 - val_loss: 455420315.2713\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f74d8ef6d10>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "RNN = initRNN()\n",
    "RNN.compile(loss='mean_squared_error', optimizer = 'adam')\n",
    "print(RNN.input_shape)\n",
    "RNN.fit(X, y, epochs = numEpoch,  batch_size=1, \n",
    "         verbose=2, validation_split = .1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(None, 1, 15)\n",
      "Train on 4406 samples, validate on 490 samples\n",
      "Epoch 1/5\n",
      " - 15s - loss: 695680252.1104 - val_loss: 460711242.7176\n",
      "Epoch 2/5\n",
      " - 12s - loss: 695452544.6383 - val_loss: 460532857.8603\n",
      "Epoch 3/5\n",
      " - 12s - loss: 695226628.1544 - val_loss: 460356309.0105\n",
      "Epoch 4/5\n",
      " - 12s - loss: 694998626.4591 - val_loss: 460178416.8427\n",
      "Epoch 5/5\n",
      " - 12s - loss: 694774150.5188 - val_loss: 460002304.3444\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f74d826b750>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "LSTM = initLSTM()\n",
    "LSTM.compile(loss='mean_squared_error', optimizer = 'adam')\n",
    "print(LSTM.input_shape)\n",
    "LSTM.fit(X, y, epochs = numEpoch,  batch_size=1, \n",
    "         verbose=2, validation_split = .1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(None, 1, 15)\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Error when checking target: expected dense_9 to have 3 dimensions, but got array with shape (4896, 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m\u001b[0m",
      "\u001b[0;31mValueError\u001b[0mTraceback (most recent call last)",
      "\u001b[0;32m<ipython-input-37-b2249c337d31>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mDense\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minput_shape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m Dense.fit(X, y, epochs = numEpoch,  batch_size=1, \n\u001b[0;32m----> 7\u001b[0;31m          verbose=2, validation_split = .1)\n\u001b[0m",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/tensorflow/python/keras/engine/training.pyc\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[1;32m   1507\u001b[0m         \u001b[0msteps_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'steps_per_epoch'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1508\u001b[0m         \u001b[0msteps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1509\u001b[0;31m         validation_split=validation_split)\n\u001b[0m\u001b[1;32m   1510\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1511\u001b[0m     \u001b[0;31m# Prepare validation data.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/tensorflow/python/keras/engine/training.pyc\u001b[0m in \u001b[0;36m_standardize_user_data\u001b[0;34m(self, x, y, sample_weight, class_weight, batch_size, check_steps, steps_name, steps, validation_split)\u001b[0m\n\u001b[1;32m    991\u001b[0m       \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnext_element\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    992\u001b[0m     x, y, sample_weights = self._standardize_weights(x, y, sample_weight,\n\u001b[0;32m--> 993\u001b[0;31m                                                      class_weight, batch_size)\n\u001b[0m\u001b[1;32m    994\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weights\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    995\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/tensorflow/python/keras/engine/training.pyc\u001b[0m in \u001b[0;36m_standardize_weights\u001b[0;34m(self, x, y, sample_weight, class_weight, batch_size)\u001b[0m\n\u001b[1;32m   1147\u001b[0m           \u001b[0mfeed_output_shapes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1148\u001b[0m           \u001b[0mcheck_batch_axis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mFalse\u001b[0m\u001b[0;34m,\u001b[0m  \u001b[0;31m# Don't enforce the batch size.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1149\u001b[0;31m           exception_prefix='target')\n\u001b[0m\u001b[1;32m   1150\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1151\u001b[0m       \u001b[0;31m# Generate sample-wise weight values given the `sample_weight` and\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/tensorflow/python/keras/engine/training_utils.pyc\u001b[0m in \u001b[0;36mstandardize_input_data\u001b[0;34m(data, names, shapes, check_batch_axis, exception_prefix)\u001b[0m\n\u001b[1;32m    314\u001b[0m                            \u001b[0;34m': expected '\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mnames\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m' to have '\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    315\u001b[0m                            \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m' dimensions, but got array '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 316\u001b[0;31m                            'with shape ' + str(data_shape))\n\u001b[0m\u001b[1;32m    317\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mcheck_batch_axis\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    318\u001b[0m           \u001b[0mdata_shape\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata_shape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Error when checking target: expected dense_9 to have 3 dimensions, but got array with shape (4896, 1)"
     ]
    }
   ],
   "source": [
    "# Need to reshape dimensions for dense, see colab notebook\n",
    "\n",
    "Dense = initDense()\n",
    "Dense.compile(loss='mean_squared_error', optimizer = 'adam')\n",
    "print(Dense.input_shape)\n",
    "Dense.fit(X, y, epochs = numEpoch,  batch_size=1, \n",
    "         verbose=2, validation_split = .1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
